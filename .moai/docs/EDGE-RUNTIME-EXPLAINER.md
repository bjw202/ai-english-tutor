# Edge Runtime으로 스트리밍 타임아웃 해결하기

쉬운 말로 설명하는 Edge Runtime 이해 가이드

## 무엇이 문제였나?

### 이해하기 쉬운 비유: 음식점 주문 문제

온라인 영어 튜터가 3명의 튜터(독해, 문법, 어휘)에게 동시에 분석을 요청합니다. 마치 음식점 주문처럼:

**Vercel 서버리스 (기존 방식) = 60초 제한 음식점**
- 손님이 주문하면 정확히 60초 안에 음식이 나와야 합니다
- 주방이 계속 준비 중이어도 60초가 지나면 강제로 손님을 내보냅니다
- 결과: 덜 익은 음식만 집에 가지고 갑니다 (불완전한 응답)

**Edge Runtime = 시간 제한 없는 편의점**
- 편의점 계산대에 직원이 바로 있습니다 (CDN 네트워크 엣지)
- 손님이 사올 때까지 기다립니다
- 음식이 완전히 준비될 때까지 기다려도 상관없습니다 (시간 제한 없음)

### 우리 앱에서 일어난 일

**프로덕션에서만 발생**:
1. 사용자가 영어 문장을 입력합니다 → `어휘 분석 시작`
2. 어휘 튜터가 6144개 토큰을 생성하기 시작합니다
3. 이건 보통 60초 이상 걸립니다
4. 60초 후 Vercel이 연결을 강제로 끊어버립니다
5. 화면에는 "완료"로 보이지만 실제로는 중간에 잘린 것입니다

## 왜 프로덕션에서만 발생했나?

### 로컬 개발 vs 프로덕션의 차이

| 항목 | 로컬 (내 컴퓨터) | 프로덕션 (Vercel) |
|------|-----------------|-----------------|
| 환경 | 직접 실행 | Vercel 클라우드 |
| 처리 방식 | 내 컴퓨터가 직접 처리 | 서버리스 함수 (60초 제한) |
| 지연 시간 | 거의 없음 | 네트워크 왕복 시간 포함 |
| 결과 | 완료될 때까지 대기 | 60초 초과 시 강제 종료 |

**왜 로컬에선 완벽했나?**
- 내 컴퓨터에는 시간 제한이 없습니다
- 어휘 튜터가 2분 걸려도 상관없습니다
- 완전한 답변을 받았기 때문에 보이지 않은 문제였습니다

**왜 프로덕션에서 터졌나?**
- Vercel의 기본 서버리스 환경: 10초 제한 (유료: 60초)
- 우리 앱은 유료로 업그레이드 되어 60초 제한이 있었습니다
- 어휘 분석이 60초를 넘으면 강제 종료됨

## Edge Runtime이 뭔가?

### 간단한 설명

Edge Runtime = "Vercel의 CDN 엣지에서 직접 실행"

```
일반 서버리스 (VM 기반):
사용자 → Vercel 데이터센터 (60초 제한) → LLM 서버

Edge Runtime (CDN 엣지):
사용자 → Vercel CDN 지역 서버 (시간 제한 없음) → LLM 서버
```

### 더 자세히

**Traditional Serverless**
- VM(가상 머신) 안에서 코드 실행
- AWS Lambda 같은 방식
- 비용 절감을 위해 시간 제한 있음 (Hobby: 10초, Pro: 60초)

**Edge Runtime**
- 전 세계 각 지역의 CDN 서버에서 바로 실행
- Cloudflare Workers처럼 동작
- 시간 제한이 없음 (사용자가 연결을 끊을 때까지 계속 실행)

### 우리 코드는 왜 Edge Runtime에서 작동할까?

```typescript
// 추가한 단 1줄!
export const runtime = 'edge';
```

이 한 줄이 Vercel에게 이렇게 말합니다:
- "이 코드는 Web API만 사용해요" → ✅ 우리 코드는 Web API 사용 중
- "시간 제한 없이 실행해도 돼" → ✅ SSE 스트리밍은 얼마나 걸리든 OK
- "CDN 엣지에서 실행하면 돼" → ✅ 속도도 향상됨

## 어떻게 고쳤나?

### 변경 사항 (극도로 간단함)

파일: `/src/app/api/tutor/analyze/route.ts`

```typescript
// 이 한 줄 추가!
export const runtime = 'edge';

export async function POST(request: Request) {
  // ... 기존 코드 ...
}
```

### 왜 이것만으로 해결되나?

1. **코드는 이미 Web API 호환**: XMLHttpRequest, Fetch API 등을 사용하지 않음
2. **SSE는 표준 Web API**: Node.js 전용이 아님
3. **LangGraph는 Edge 호환**: HTTP 호출만 하면 됨
4. **따라서 리팩토링 불필요**: 우리 코드는 이미 Edge Runtime 준비됨

## 앞으로 비슷한 문제 예방법

### 1. 장시간 스트리밍을 사용할 땐?

```
필수: export const runtime = 'edge';
이유: 시간 제한 없이 안전하게 스트리밍 가능
```

### 2. SSE 하트비트는 여전히 필요한가?

```
이미지 분석에는 여전히 필요함!
이유: 네트워크 중간 노드들이 유휴 연결 종료 가능
(Vercel의 60초 제한은 아니지만 다른 곳에서 발생 가능)
```

### 3. 새로운 장시간 작업 추가할 때?

체크리스트:
- [ ] `export const runtime = 'edge';` 설정
- [ ] SSE 또는 WebSocket 사용 (HTTP polling 피하기)
- [ ] 장시간 작업은 SSE 하트비트 유지
- [ ] 로컬 테스트 + 프로덕션 테스트

## 요약: 한 번에 이해하기

| 항목 | 전 (서버리스) | 후 (Edge) |
|------|-------------|---------|
| 실행 환경 | 데이터센터 VM | CDN 엣지 |
| 시간 제한 | 60초 | 없음 |
| 어휘 분석 (6144 토큰) | ❌ 60초 초과 → 강제 종료 | ✅ 완전히 완료 |
| 응답 속도 | 느림 | 빠름 |
| 코드 변경 | 대규모 리팩토링 필요? | 1줄 추가 |
| 필요한 기술 | Node.js 전용 기능 | Web API만 필요 |

## 기술 용어 설명

**SSE (Server-Sent Events)**
- 서버가 클라이언트에게 계속 데이터를 보냄
- 실시간 타이핑 효과를 만듦
- 일방향 통신 (서버 → 클라이언트)

**토큰**
- LLM이 처리하는 텍스트의 작은 단위
- 보통 4자 ≈ 1토큰
- 6144 토큰 ≈ 2만 4576자

**Web API**
- 브라우저와 서버 모두에서 지원하는 표준 기능
- Fetch API, EventSource, Promise 등
- Node.js만의 기능이 아님

**CDN (Content Delivery Network)**
- 전 세계 곳곳에 배치된 서버들
- 사용자 가까운 곳에서 콘텐츠 제공
- 더 빠른 응답 속도

---

**작성일**: 2026-02-26
**관련 SPEC**: SPEC-VOCAB-003 (Unified Streaming Architecture)
**참고**: `.moai/learning/IMAGE-ANALYSIS-DEPLOYMENT-LEARNINGS.md`
